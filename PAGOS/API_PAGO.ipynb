{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "# !pip install imaplib email pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import html\n",
    "import locale\n",
    "from email.utils import parsedate_to_datetime\n",
    "from pytz import timezone\n",
    "import logging\n",
    "\n",
    "# Configuración de la cuenta\n",
    "IMAP_SERVER = \"imap-mail.outlook.com\"\n",
    "EMAIL_ACCOUNT = \"facturas_gpf@outlook.com\"\n",
    "APP_PASSWORD = \"lleibtocysmvsnko\"\n",
    "\n",
    "# Configurar el log\n",
    "logging.basicConfig(filename='procesamiento_emails.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Conectar al servidor IMAP\n",
    "try:\n",
    "    mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
    "    mail.login(EMAIL_ACCOUNT, APP_PASSWORD)\n",
    "    logging.info('Conexión al servidor IMAP exitosa')\n",
    "except Exception as e:\n",
    "    logging.error(f'Error al conectar al servidor IMAP: {e}')\n",
    "    raise\n",
    "\n",
    "mail.select(\"inbox\")\n",
    "\n",
    "# Obtener las fechas de hoy, ayer y mañana en formato inglés\n",
    "locale.setlocale(locale.LC_TIME, 'en_US.UTF-8')\n",
    "date_today = datetime.now().strftime(\"%d-%b-%Y\")\n",
    "date_yesterday = (datetime.now() - timedelta(1)).strftime(\"%d-%b-%Y\")\n",
    "date_tomorrow = (datetime.now() + timedelta(1)).strftime(\"%d-%b-%Y\")\n",
    "locale.setlocale(locale.LC_TIME, '')  # Restaurar la configuración regional por defecto\n",
    "\n",
    "# Buscar correos de ayer, hoy y mañana\n",
    "try:\n",
    "    status_today, messages_today = mail.search(None, f'(ON {date_today})')\n",
    "    status_yesterday, messages_yesterday = mail.search(None, f'(ON {date_yesterday})')\n",
    "    status_tomorrow, messages_tomorrow = mail.search(None, f'(ON {date_tomorrow})')\n",
    "    logging.info(f'Búsqueda de correos exitosa, estado hoy: {status_today}, estado ayer: {status_yesterday}, estado mañana (por cambio zona horaria): {status_tomorrow}')\n",
    "except Exception as e:\n",
    "    logging.error(f'Error al buscar correos: {e}')\n",
    "    raise\n",
    "\n",
    "messages = messages_today[0].split() + messages_yesterday[0].split() + messages_tomorrow[0].split()\n",
    "logging.info(f'Total de correos encontrados: {len(messages)}')\n",
    "\n",
    "processed_emails = []\n",
    "\n",
    "# Leer archivo pickle para evitar duplicados\n",
    "try:\n",
    "    with open('processed_emails.pkl', 'rb') as f:\n",
    "        processed_data = pickle.load(f)\n",
    "    logging.info('Archivo pickle de correos procesados cargado correctamente')\n",
    "except FileNotFoundError:\n",
    "    processed_data = {}\n",
    "    logging.info('Archivo pickle no encontrado, iniciando con datos vacíos')\n",
    "\n",
    "def extract_data_from_xml(xml_path):\n",
    "    try:\n",
    "        with open(xml_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(xml_path, 'r', encoding='ISO-8859-1', errors='replace') as file:\n",
    "            content = file.read()\n",
    "\n",
    "    content = html.unescape(content)\n",
    "    \n",
    "    patterns = {\n",
    "        'ruc': r'<ruc>(.*?)<\\/ruc>',\n",
    "        'estab': r'<estab>(.*?)<\\/estab>',\n",
    "        'ptoEmi': r'<ptoEmi>(.*?)<\\/ptoEmi>',\n",
    "        'secuencial': r'<secuencial>(.*?)<\\/secuencial>',\n",
    "        'total_sin_impuestos': r'<totalSinImpuestos>(.*?)<\\/totalSinImpuestos>',\n",
    "        'fecha_emision': r'<fechaEmision>(.*?)<\\/fechaEmision>',\n",
    "        'nombre_comercial': r'<razonSocial>(.*?)<\\/razonSocial>',\n",
    "        'compania': r'<razonSocialComprador>(.*?)<\\/razonSocialComprador>'\n",
    "    }\n",
    "    \n",
    "    extracted_data = {key: (match.group(1) if (match := re.search(pattern, content)) else '') for key, pattern in patterns.items()}\n",
    "    \n",
    "    subtotales = {}\n",
    "    iva_values = {}\n",
    "\n",
    "    # Buscar en la etiqueta \"detalle\" -> \"impuestos\" -> \"impuesto\"\n",
    "    detalle_pattern = r'<detalle>(.*?)<\\/detalle>'\n",
    "    detalle_matches = re.findall(detalle_pattern, content, re.DOTALL)\n",
    "\n",
    "    for detalle in detalle_matches:\n",
    "        impuestos_pattern = r'<impuesto>(.*?)<\\/impuesto>'\n",
    "        impuestos_matches = re.findall(impuestos_pattern, detalle, re.DOTALL)\n",
    "\n",
    "        for impuesto in impuestos_matches:\n",
    "            base_imponible_pattern = r'<baseImponible>(.*?)<\\/baseImponible>'\n",
    "            tarifa_pattern = r'<tarifa>(.*?)<\\/tarifa>'\n",
    "            valor_pattern = r'<valor>(.*?)<\\/valor>'\n",
    "\n",
    "            base_imponible = re.search(base_imponible_pattern, impuesto)\n",
    "            tarifa = re.search(tarifa_pattern, impuesto)\n",
    "            valor = re.search(valor_pattern, impuesto)\n",
    "\n",
    "            if base_imponible and tarifa and valor:\n",
    "                base_imponible = float(base_imponible.group(1))\n",
    "                tarifa = float(tarifa.group(1))\n",
    "                valor = float(valor.group(1))\n",
    "\n",
    "                if tarifa not in subtotales:\n",
    "                    subtotales[tarifa] = 0\n",
    "                if tarifa not in iva_values:\n",
    "                    iva_values[tarifa] = 0\n",
    "\n",
    "                subtotales[tarifa] += base_imponible\n",
    "                iva_values[tarifa] += valor\n",
    "\n",
    "    if not subtotales and not iva_values:\n",
    "        total_impuestos_pattern = r'<totalImpuesto>(.*?)<\\/totalImpuesto>'\n",
    "        total_impuestos_matches = re.findall(total_impuestos_pattern, content, re.DOTALL)\n",
    "\n",
    "        for total_impuesto in total_impuestos_matches:\n",
    "            base_imponible_pattern = r'<baseImponible>(.*?)<\\/baseImponible>'\n",
    "            tarifa_pattern = r'<tarifa>(.*?)<\\/tarifa>'\n",
    "            valor_pattern = r'<valor>(.*?)<\\/valor>'\n",
    "\n",
    "            base_imponible = re.search(base_imponible_pattern, total_impuesto)\n",
    "            tarifa = re.search(tarifa_pattern, total_impuesto)\n",
    "            valor = re.search(valor_pattern, total_impuesto)\n",
    "\n",
    "            if base_imponible and tarifa and valor:\n",
    "                base_imponible = float(base_imponible.group(1))\n",
    "                tarifa = float(tarifa.group(1))\n",
    "                valor = float(valor.group(1))\n",
    "\n",
    "                if tarifa not in subtotales:\n",
    "                    subtotales[tarifa] = 0\n",
    "                if tarifa not in iva_values:\n",
    "                    iva_values[tarifa] = 0\n",
    "\n",
    "                subtotales[tarifa] += base_imponible\n",
    "                iva_values[tarifa] += valor\n",
    "\n",
    "    return extracted_data, subtotales, iva_values\n",
    "\n",
    "def decode_payload(part):\n",
    "    payload = part.get_payload(decode=True)\n",
    "    encodings = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            return payload.decode(enc)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return payload.decode('utf-8', errors='replace')\n",
    "\n",
    "def format_date(date_str):\n",
    "    date_obj = parsedate_to_datetime(date_str)\n",
    "    ecuador_tz = timezone('America/Guayaquil')\n",
    "    localized_date = date_obj.astimezone(ecuador_tz)\n",
    "    return localized_date.strftime('%d/%m/%Y'), localized_date.strftime('%H:%M:%S')\n",
    "\n",
    "def extract_oc_numbers(body):\n",
    "    oc_pattern = r'OC[\\s.]*[:]*[\\s]*(\\d+(?:[\\s,-]+[\\s]*\\d+)*)'\n",
    "    oc_matches = re.findall(oc_pattern, body, re.IGNORECASE)\n",
    "    logging.debug(f'OCs encontradas: {oc_matches}')\n",
    "\n",
    "    oc_numbers = []\n",
    "    for match in oc_matches:\n",
    "        numbers = re.split(r'[\\s,-]+', match.strip())\n",
    "        oc_numbers.extend(numbers)\n",
    "\n",
    "    result = ' - '.join(filter(None, oc_numbers))\n",
    "    logging.debug(f'Números de OC extraídos: {result}')\n",
    "    return result\n",
    "\n",
    "def extract_original_sender(body):\n",
    "    # Patrón para buscar el remitente original en el cuerpo del correo reenviado\n",
    "    original_sender_pattern = r'De:\\s*([^<]+)<([^>]+)>'\n",
    "    match = re.search(original_sender_pattern, body, re.IGNORECASE)\n",
    "    if match:\n",
    "        name = match.group(1).strip()\n",
    "        email = match.group(2).strip()\n",
    "        return f\"{name} <{email}>\"\n",
    "    return None\n",
    "\n",
    "def process_message(msg_num):\n",
    "    status, msg_data = mail.fetch(msg_num, \"(RFC822)\")\n",
    "    if status != 'OK':\n",
    "        logging.error(f'Error al obtener el mensaje número: {msg_num}')\n",
    "        return\n",
    "    \n",
    "    msg = email.message_from_bytes(msg_data[0][1])\n",
    "    subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
    "    if isinstance(subject, bytes):\n",
    "        subject = subject.decode(encoding if encoding else \"utf-8\")\n",
    "    sender = msg.get(\"From\")\n",
    "    date = msg.get(\"Date\")\n",
    "    formatted_date, formatted_time = format_date(date)\n",
    "    logging.info(f'Procesando mensaje de: {sender}, fecha: {formatted_date}, hora: {formatted_time}, asunto: {subject}')\n",
    "    \n",
    "    body = \"\"\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == \"text/plain\":\n",
    "                body += decode_payload(part)\n",
    "    else:\n",
    "        body = decode_payload(msg)\n",
    "    \n",
    "    # Intentar extraer el remitente original del cuerpo del correo\n",
    "    original_sender = extract_original_sender(body)\n",
    "    if original_sender:\n",
    "        sender = original_sender\n",
    "\n",
    "    oc_numbers = extract_oc_numbers(body)\n",
    "    if oc_numbers:\n",
    "        secuencial = re.search(r'FACTURA[\\s-]*(\\d+-\\d+-\\d+)', subject, re.IGNORECASE)\n",
    "        if secuencial:\n",
    "            secuencial = secuencial.group(1)\n",
    "            if (secuencial, oc_numbers) not in processed_data:\n",
    "                processed_data[(secuencial, oc_numbers)] = True\n",
    "                email_data = {\n",
    "                    \"remitente\": sender,\n",
    "                    \"fecha\": formatted_date,\n",
    "                    \"hora\": formatted_time,\n",
    "                    \"asunto\": subject,\n",
    "                    \"ocs\": oc_numbers,\n",
    "                    \"Factura\": secuencial\n",
    "                }\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_maintype() == \"multipart\":\n",
    "                        continue\n",
    "                    if part.get(\"Content-Disposition\") is None:\n",
    "                        continue\n",
    "                    filename = part.get_filename()\n",
    "                    if filename and filename.endswith(\".xml\"):\n",
    "                        xml_filename = filename\n",
    "                        xml_part = part\n",
    "                    elif filename and filename.endswith(\".pdf\"):\n",
    "                        pdf_filename = filename\n",
    "                        pdf_part = part\n",
    "                if xml_filename and pdf_filename:\n",
    "                    xml_base = os.path.splitext(xml_filename)[0]\n",
    "                    pdf_base = os.path.splitext(pdf_filename)[0]\n",
    "                    if xml_base == pdf_base:\n",
    "                        folder_name = subject.replace(\"/\", \"_\")\n",
    "                        if not os.path.isdir(folder_name):\n",
    "                            os.mkdir(folder_name)\n",
    "                        xml_path = os.path.join(folder_name, xml_filename)\n",
    "                        pdf_path = os.path.join(folder_name, pdf_filename)\n",
    "                        with open(xml_path, \"wb\") as f:\n",
    "                            f.write(xml_part.get_payload(decode=True))\n",
    "                        with open(pdf_path, \"wb\") as f:\n",
    "                            f.write(pdf_part.get_payload(decode=True))\n",
    "                        xml_info, subtotales, iva_values = extract_data_from_xml(xml_path)\n",
    "                        subtotal_columns = {f\"subtotal_{tarifa}%\": subtotal for tarifa, subtotal in subtotales.items()}\n",
    "                        iva_columns = {f\"IVA_{tarifa}%\": iva for tarifa, iva in iva_values.items()}\n",
    "                        email_data.update({\n",
    "                            \"ruc\": xml_info['ruc'],\n",
    "                            \"total_sin_impuestos\": float(xml_info['total_sin_impuestos']),\n",
    "                            \"fecha_emision\": xml_info['fecha_emision'],\n",
    "                            \"nombre_comercial\": xml_info['nombre_comercial'],\n",
    "                            \"compania\": xml_info['compania'],\n",
    "                        })\n",
    "                        email_data.update(subtotal_columns)\n",
    "                        email_data.update(iva_columns)\n",
    "                        processed_emails.append(email_data)\n",
    "                        logging.info(f'Email data procesada y agregada: {email_data}')\n",
    "                        if os.path.exists(xml_path):\n",
    "                            os.remove(xml_path)\n",
    "                        if os.path.exists(pdf_path):\n",
    "                            os.remove(pdf_path)\n",
    "                        if not os.listdir(folder_name):\n",
    "                            os.rmdir(folder_name)\n",
    "                    else:\n",
    "                        logging.info(f'Mensaje sin archivos adjuntos XML y PDF correspondientes: {subject}')\n",
    "                else:\n",
    "                    logging.info(f'No se encontraron OCs en el msj: {subject}')\n",
    "\n",
    "\n",
    "# Procesar los mensajes\n",
    "for msg_num in messages:\n",
    "    process_message(msg_num)\n",
    "\n",
    "# Crear DataFrame si hay correos procesados\n",
    "if processed_emails:\n",
    "    df = pd.DataFrame(processed_emails)\n",
    "    column_order = [\"remitente\", \"fecha\", \"hora\", \"asunto\", \"ocs\", \"Factura\", \"ruc\", \"total_sin_impuestos\"]\n",
    "    subtotal_iva_columns = [col for col in df.columns if col.startswith(\"subtotal_\") or col.startswith(\"IVA_\")]\n",
    "    column_order.extend(subtotal_iva_columns)\n",
    "    column_order.extend([col for col in df.columns if col not in column_order])\n",
    "    \n",
    "    # Verificar que las columnas existen en el DataFrame antes de reordenar\n",
    "    column_order = [col for col in column_order if col in df.columns]\n",
    "    \n",
    "    df = df[column_order]\n",
    "    df.to_excel(\"processed_emails.xlsx\", index=False)\n",
    "else:\n",
    "    logging.info('No se encontraron correos para procesar en las fechas especificadas.')\n",
    "    # Crear un archivo Excel vacío con las columnas necesarias\n",
    "    df = pd.DataFrame(columns=[\"remitente\", \"fecha\", \"hora\", \"asunto\", \"ocs\", \"Factura\", \"ruc\", \"total_sin_impuestos\"])\n",
    "    df.to_excel(\"processed_emails.xlsx\", index=False)\n",
    "\n",
    "# Guardar el archivo pickle actualizado\n",
    "with open('processed_emails.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_data, f)\n",
    "\n",
    "# Cerrar la conexión IMAP y el log\n",
    "mail.close()\n",
    "mail.logout()\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_tabla_excel_y_limpieza(ruta_excel_salida, access_token):\n",
    "    # Verifica si el archivo existe, si no, crea un archivo vacío con una hoja inicial\n",
    "    inicializar = not os.path.exists(ruta_excel_salida)\n",
    "    if inicializar:\n",
    "        with pd.ExcelWriter(ruta_excel_salida, engine='openpyxl') as writer:\n",
    "            pd.DataFrame().to_excel(writer, sheet_name='Hoja_Temporal', index=False)  # Crea una hoja temporal vacía\n",
    "\n",
    "    # Asumiendo que `current_dir`, `pickle_file`, y `csv_oc_pendientes` están definidos en el ámbito global o importados previamente\n",
    "    archivos = glob.glob(os.path.join(current_dir, 'OCS', '**', '*.xml'), recursive=True)\n",
    "    dataframe_total = pd.DataFrame()\n",
    "\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        facturas_procesadas = pickle.load(f)\n",
    "    df_oc_pendientes = pd.read_csv(csv_oc_pendientes)\n",
    "\n",
    "    for ruta_archivo in archivos:\n",
    "        informacion, subtotales, iva_values = extraer_informacion_de_archivo(ruta_archivo)\n",
    "        factura = f\"{informacion['estab']}-{informacion['ptoEmi']}-{informacion['secuencial']}\"\n",
    "        oc = informacion['OC']\n",
    "\n",
    "        if oc not in facturas_procesadas:\n",
    "            facturas_procesadas[oc] = True\n",
    "            descripcion = informacion['descripciones']\n",
    "\n",
    "            # Preparar las nuevas columnas\n",
    "            subtotal_0 = subtotales.get(0, 0)\n",
    "            tarifas_no_0 = \";\".join([str(tarifa) for tarifa in subtotales if tarifa != 0])\n",
    "            subtotales_impuesto_no_0 = \";\".join([str(subtotales[tarifa]) for tarifa in subtotales if tarifa != 0])\n",
    "            iva_no_0 = \";\".join([str(iva_values[tarifa]) for tarifa in iva_values if tarifa != 0])\n",
    "\n",
    "            dataframe_temporal = pd.DataFrame({\n",
    "                'Autorizacion': [informacion[\"autorizacion\"]],\n",
    "                'RUC': [informacion['ruc']],\n",
    "                'Tercero': [informacion['Tercero']],\n",
    "                'Nombre Comercial': [informacion['nombre_comercial']],\n",
    "                'Compañía': [informacion['compania']],\n",
    "                'Centro de Costo': [informacion['Centro de Costo']],\n",
    "                'Nombre Farmacia': [informacion['Nombre Farmacia']],\n",
    "                'Factura': [factura],\n",
    "                'Fecha': [informacion['fecha_formateada']],\n",
    "                'OC': [oc],\n",
    "                'Frecuencia facturación': [informacion['Frecuencia facturación']],\n",
    "                'Descripcion': [descripcion],\n",
    "                'Subtotal 0%': [subtotal_0],\n",
    "                'Tarifa': [tarifas_no_0],\n",
    "                'Subtotales Impuesto': [subtotales_impuesto_no_0],\n",
    "                'IVA': [iva_no_0]\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('processed_emails.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "print(processed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
